{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fsdl-text-recognizer-2021-lab-1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP8Tpbb79HkUwB6ZbvayZQk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/razormin/full-stack-deep-learning/blob/main/fsdl_text_recognizer_2021_lab_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wL0-QrKtIgL",
        "outputId": "83e4e65d-7514-4646-9240-a3fb8d747828"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Jul 30 23:39:01 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   55C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlRXTT2WtQgA",
        "outputId": "ab45b93f-5254-48c4-ab34-702b6335c275"
      },
      "source": [
        "# FSDL Spring 2021 Setup\n",
        "!git clone https://github.com/full-stack-deep-learning/fsdl-text-recognizer-2021-labs\n",
        "%cd fsdl-text-recognizer-2021-labs\n",
        "!pip3 install boltons wandb pytorch_lightning==1.1.4 pip install torch==1.7.1+cu110 torchvision==0.8.2+cu110 torchaudio==0.7.2 torchtext==0.8.1 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "%env PYTHONPATH=.:$PYTHONPATH"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'fsdl-text-recognizer-2021-labs'...\n",
            "remote: Enumerating objects: 798, done.\u001b[K\n",
            "remote: Counting objects: 100% (230/230), done.\u001b[K\n",
            "remote: Compressing objects: 100% (88/88), done.\u001b[K\n",
            "remote: Total 798 (delta 162), reused 143 (delta 142), pack-reused 568\u001b[K\n",
            "Receiving objects: 100% (798/798), 18.88 MiB | 22.64 MiB/s, done.\n",
            "Resolving deltas: 100% (400/400), done.\n",
            "/content/fsdl-text-recognizer-2021-labs\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting boltons\n",
            "  Downloading boltons-21.0.0-py2.py3-none-any.whl (193 kB)\n",
            "\u001b[K     |████████████████████████████████| 193 kB 8.4 MB/s \n",
            "\u001b[?25hCollecting wandb\n",
            "  Downloading wandb-0.11.1-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 65.1 MB/s \n",
            "\u001b[?25hCollecting pytorch_lightning==1.1.4\n",
            "  Downloading pytorch_lightning-1.1.4-py3-none-any.whl (684 kB)\n",
            "\u001b[K     |████████████████████████████████| 684 kB 43.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n",
            "Requirement already satisfied: install in /usr/local/lib/python3.7/dist-packages (1.3.4)\n",
            "Collecting torch==1.7.1+cu110\n",
            "  Downloading https://download.pytorch.org/whl/cu110/torch-1.7.1%2Bcu110-cp37-cp37m-linux_x86_64.whl (1156.8 MB)\n",
            "\u001b[K     |███████████████████████         | 834.1 MB 1.3 MB/s eta 0:04:10tcmalloc: large alloc 1147494400 bytes == 0x557c179b6000 @  0x7f5c6df96615 0x557bde9a702c 0x557bdea8717a 0x557bde9a9e4d 0x557bdea9bc0d 0x557bdea1e0d8 0x557bdea18c35 0x557bde9ab73a 0x557bdea1df40 0x557bdea18c35 0x557bde9ab73a 0x557bdea1a93b 0x557bdea9ca56 0x557bdea19fb3 0x557bdea9ca56 0x557bdea19fb3 0x557bdea9ca56 0x557bdea19fb3 0x557bde9abb99 0x557bde9eee79 0x557bde9aa7b2 0x557bdea1de65 0x557bdea18c35 0x557bde9ab73a 0x557bdea1a93b 0x557bdea18c35 0x557bde9ab73a 0x557bdea19b0e 0x557bde9ab65a 0x557bdea19d67 0x557bdea18c35\n",
            "\u001b[K     |█████████████████████████████▏  | 1055.7 MB 1.2 MB/s eta 0:01:26tcmalloc: large alloc 1434370048 bytes == 0x557c5c00c000 @  0x7f5c6df96615 0x557bde9a702c 0x557bdea8717a 0x557bde9a9e4d 0x557bdea9bc0d 0x557bdea1e0d8 0x557bdea18c35 0x557bde9ab73a 0x557bdea1df40 0x557bdea18c35 0x557bde9ab73a 0x557bdea1a93b 0x557bdea9ca56 0x557bdea19fb3 0x557bdea9ca56 0x557bdea19fb3 0x557bdea9ca56 0x557bdea19fb3 0x557bde9abb99 0x557bde9eee79 0x557bde9aa7b2 0x557bdea1de65 0x557bdea18c35 0x557bde9ab73a 0x557bdea1a93b 0x557bdea18c35 0x557bde9ab73a 0x557bdea19b0e 0x557bde9ab65a 0x557bdea19d67 0x557bdea18c35\n",
            "\u001b[K     |████████████████████████████████| 1156.7 MB 1.2 MB/s eta 0:00:01tcmalloc: large alloc 1445945344 bytes == 0x557cb17f8000 @  0x7f5c6df96615 0x557bde9a702c 0x557bdea8717a 0x557bde9a9e4d 0x557bdea9bc0d 0x557bdea1e0d8 0x557bdea18c35 0x557bde9ab73a 0x557bdea19d67 0x557bdea18c35 0x557bde9ab73a 0x557bdea19d67 0x557bdea18c35 0x557bde9ab73a 0x557bdea19d67 0x557bdea18c35 0x557bde9ab73a 0x557bdea19d67 0x557bdea18c35 0x557bde9ab73a 0x557bdea19d67 0x557bde9ab65a 0x557bdea19d67 0x557bdea18c35 0x557bde9ab73a 0x557bdea1a93b 0x557bdea18c35 0x557bde9ab73a 0x557bdea1a93b 0x557bdea18c35 0x557bde9abdd1\n",
            "\u001b[K     |████████████████████████████████| 1156.8 MB 14 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.8.2+cu110\n",
            "  Downloading https://download.pytorch.org/whl/cu110/torchvision-0.8.2%2Bcu110-cp37-cp37m-linux_x86_64.whl (12.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.9 MB 163 kB/s \n",
            "\u001b[?25hCollecting torchaudio==0.7.2\n",
            "  Downloading torchaudio-0.7.2-cp37-cp37m-manylinux1_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 21.5 MB/s \n",
            "\u001b[?25hCollecting torchtext==0.8.1\n",
            "  Downloading torchtext-0.8.1-cp37-cp37m-manylinux1_x86_64.whl (7.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.0 MB 34.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.1.4) (2.5.0)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.1.4) (1.19.5)\n",
            "Collecting fsspec[http]>=0.8.1\n",
            "  Downloading fsspec-2021.7.0-py3-none-any.whl (118 kB)\n",
            "\u001b[K     |████████████████████████████████| 118 kB 64.5 MB/s \n",
            "\u001b[?25hCollecting PyYAML>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 53.7 MB/s \n",
            "\u001b[?25hCollecting future>=0.17.1\n",
            "  Downloading future-0.18.2.tar.gz (829 kB)\n",
            "\u001b[K     |████████████████████████████████| 829 kB 54.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.1.4) (4.41.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1+cu110) (3.7.4.3)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.2+cu110) (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.1) (2.23.0)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 52.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.1.4) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.1.4) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.1.4) (0.4.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.1.4) (0.6.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.1.4) (1.32.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.1.4) (1.8.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.1.4) (0.36.2)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.1.4) (3.17.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.1.4) (57.2.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.1.4) (1.34.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.1.4) (0.12.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=2.2.0->pytorch_lightning==1.1.4) (1.15.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning==1.1.4) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning==1.1.4) (4.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning==1.1.4) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning==1.1.4) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning==1.1.4) (4.6.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning==1.1.4) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.1) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.1) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.1) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.1) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning==1.1.4) (3.1.1)\n",
            "Collecting configparser>=3.8.1\n",
            "  Downloading configparser-5.0.2-py3-none-any.whl (19 kB)\n",
            "Collecting graphql-core>=2.3.0\n",
            "  Downloading graphql_core-3.1.5-py3-none-any.whl (188 kB)\n",
            "\u001b[K     |████████████████████████████████| 188 kB 66.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.1-py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.1)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.18-py3-none-any.whl (170 kB)\n",
            "\u001b[K     |████████████████████████████████| 170 kB 63.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.3.1-py2.py3-none-any.whl (133 kB)\n",
            "\u001b[K     |████████████████████████████████| 133 kB 69.1 MB/s \n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.7-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.2 MB/s \n",
            "\u001b[?25hCollecting smmap<5,>=3.0.1\n",
            "  Downloading smmap-4.0.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[K     |████████████████████████████████| 294 kB 57.0 MB/s \n",
            "\u001b[?25hCollecting async-timeout<4.0,>=3.0\n",
            "  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch_lightning==1.1.4) (21.2.0)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[K     |████████████████████████████████| 142 kB 59.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning==1.1.4) (3.5.0)\n",
            "Building wheels for collected packages: future, pathtools\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=00db590153df164f1e1801b865155214341435bc82debe25f39320e8d10d5669\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=f557c32a05c1b42797eb7ff258598a4704f83b134140242aceb608c3a2ce0468\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "Successfully built future pathtools\n",
            "Installing collected packages: multidict, yarl, smmap, async-timeout, gitdb, fsspec, aiohttp, torch, shortuuid, sentry-sdk, PyYAML, pathtools, graphql-core, GitPython, future, docker-pycreds, configparser, wandb, torchvision, torchtext, torchaudio, pytorch-lightning, boltons\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.9.0+cu102\n",
            "    Uninstalling torch-1.9.0+cu102:\n",
            "      Successfully uninstalled torch-1.9.0+cu102\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLyzyY__u0t9",
        "outputId": "346fdb56-06f5-4c8c-c898-e2142f32108a"
      },
      "source": [
        "cd lab1"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/fsdl-text-recognizer-2021-labs/lab1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_M9AeXF_u276",
        "outputId": "8e9aa41d-0412-4b59-9afc-757610bc04e4"
      },
      "source": [
        "!python training/run_experiment.py --max_epochs=3"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: You have set progress_bar_refresh_rate < 20 on Google Colab. This may crash. Consider using progress_bar_refresh_rate >= 20 in Trainer.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "GPU available: True, used: False\n",
            "TPU available: None, using: 0 TPU cores\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: GPU available but not used. Set the --gpus flag when calling the script.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /content/fsdl-text-recognizer-2021-labs/data/downloaded/MNIST/raw/train-images-idx3-ubyte.gz\n",
            "100% 9904128/9912422 [00:39<00:00, 254740.53it/s]Extracting /content/fsdl-text-recognizer-2021-labs/data/downloaded/MNIST/raw/train-images-idx3-ubyte.gz to /content/fsdl-text-recognizer-2021-labs/data/downloaded/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /content/fsdl-text-recognizer-2021-labs/data/downloaded/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "\n",
            "0it [00:00, ?it/s]\u001b[A\n",
            "32768it [00:00, 133520.01it/s]\n",
            "Extracting /content/fsdl-text-recognizer-2021-labs/data/downloaded/MNIST/raw/train-labels-idx1-ubyte.gz to /content/fsdl-text-recognizer-2021-labs/data/downloaded/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /content/fsdl-text-recognizer-2021-labs/data/downloaded/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "\n",
            "0it [00:00, ?it/s]\u001b[A\n",
            "  0% 0/1648877 [00:00<?, ?it/s]\u001b[A\n",
            "  2% 40960/1648877 [00:00<00:06, 254090.46it/s]\u001b[A\n",
            "  7% 122880/1648877 [00:00<00:04, 307595.07it/s]\u001b[A\n",
            " 11% 188416/1648877 [00:00<00:04, 359217.83it/s]\u001b[A\n",
            " 14% 237568/1648877 [00:00<00:03, 359883.07it/s]\u001b[A\n",
            " 17% 278528/1648877 [00:00<00:04, 323327.62it/s]\u001b[A\n",
            " 19% 311296/1648877 [00:01<00:04, 300079.08it/s]\u001b[A\n",
            " 21% 344064/1648877 [00:01<00:04, 284122.82it/s]\u001b[A\n",
            " 23% 376832/1648877 [00:01<00:04, 273734.71it/s]\u001b[A\n",
            " 25% 409600/1648877 [00:01<00:04, 266318.02it/s]\u001b[A\n",
            " 27% 442368/1648877 [00:01<00:04, 263291.17it/s]\u001b[A\n",
            " 29% 475136/1648877 [00:01<00:04, 259674.95it/s]\u001b[A\n",
            " 31% 507904/1648877 [00:01<00:04, 257452.91it/s]\u001b[A\n",
            " 33% 540672/1648877 [00:01<00:04, 258309.67it/s]\u001b[A\n",
            " 35% 573440/1648877 [00:02<00:04, 256171.19it/s]\u001b[A\n",
            " 37% 606208/1648877 [00:02<00:04, 256203.15it/s]\u001b[A\n",
            " 39% 638976/1648877 [00:02<00:03, 255847.63it/s]\u001b[A\n",
            " 41% 671744/1648877 [00:02<00:03, 255241.92it/s]\u001b[A\n",
            " 43% 704512/1648877 [00:02<00:03, 255182.13it/s]\u001b[A\n",
            " 45% 737280/1648877 [00:02<00:03, 254417.67it/s]\u001b[A\n",
            " 47% 770048/1648877 [00:02<00:03, 254662.89it/s]\u001b[A\n",
            " 49% 802816/1648877 [00:02<00:03, 252937.68it/s]\u001b[A\n",
            " 51% 835584/1648877 [00:03<00:03, 253488.37it/s]\u001b[A\n",
            " 53% 868352/1648877 [00:03<00:03, 254301.15it/s]\u001b[A\n",
            " 55% 901120/1648877 [00:03<00:02, 255177.86it/s]\u001b[A\n",
            " 57% 933888/1648877 [00:03<00:02, 254874.00it/s]\u001b[A\n",
            " 59% 966656/1648877 [00:03<00:02, 254782.68it/s]\u001b[A\n",
            " 61% 999424/1648877 [00:03<00:02, 252672.91it/s]\u001b[A\n",
            " 63% 1032192/1648877 [00:03<00:02, 255136.59it/s]\u001b[A\n",
            " 65% 1064960/1648877 [00:03<00:02, 254849.86it/s]\u001b[A\n",
            " 67% 1097728/1648877 [00:04<00:02, 252499.63it/s]\u001b[A\n",
            " 69% 1130496/1648877 [00:04<00:02, 255261.41it/s]\u001b[A\n",
            " 71% 1163264/1648877 [00:04<00:01, 254909.08it/s]\u001b[A\n",
            " 73% 1196032/1648877 [00:04<00:01, 254553.79it/s]\u001b[A\n",
            " 75% 1228800/1648877 [00:04<00:01, 254582.37it/s]\u001b[A\n",
            " 77% 1261568/1648877 [00:04<00:01, 253875.49it/s]\u001b[A\n",
            " 78% 1294336/1648877 [00:04<00:01, 253637.76it/s]\u001b[A\n",
            " 80% 1327104/1648877 [00:05<00:01, 253276.41it/s]\u001b[A\n",
            " 82% 1359872/1648877 [00:05<00:01, 255138.04it/s]\u001b[A\n",
            " 84% 1392640/1648877 [00:05<00:01, 254715.27it/s]\u001b[A\n",
            " 86% 1425408/1648877 [00:05<00:00, 254378.49it/s]\u001b[A\n",
            " 88% 1458176/1648877 [00:05<00:00, 248040.11it/s]\u001b[A\n",
            " 90% 1490944/1648877 [00:05<00:00, 256214.53it/s]\u001b[A\n",
            " 92% 1523712/1648877 [00:05<00:00, 254731.70it/s]\u001b[A\n",
            " 94% 1556480/1648877 [00:05<00:00, 254978.81it/s]\u001b[A\n",
            " 96% 1589248/1648877 [00:06<00:00, 255412.39it/s]\u001b[A\n",
            " 98% 1622016/1648877 [00:06<00:00, 254641.52it/s]\u001b[A\n",
            "1654784it [00:06, 249902.58it/s]                 \u001b[AExtracting /content/fsdl-text-recognizer-2021-labs/data/downloaded/MNIST/raw/t10k-images-idx3-ubyte.gz to /content/fsdl-text-recognizer-2021-labs/data/downloaded/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /content/fsdl-text-recognizer-2021-labs/data/downloaded/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "\n",
            "\n",
            "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "8192it [00:00, 9324.86it/s] \n",
            "Extracting /content/fsdl-text-recognizer-2021-labs/data/downloaded/MNIST/raw/t10k-labels-idx1-ubyte.gz to /content/fsdl-text-recognizer-2021-labs/data/downloaded/MNIST/raw\n",
            "Processing...\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n",
            "Done!\n",
            "2021-07-26 00:00:37.567001: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "\n",
            "  | Name          | Type     | Params\n",
            "-------------------------------------------\n",
            "0 | model         | MLP      | 936 K \n",
            "1 | model.dropout | Dropout  | 0     \n",
            "2 | model.fc1     | Linear   | 803 K \n",
            "3 | model.fc2     | Linear   | 131 K \n",
            "4 | model.fc3     | Linear   | 1.3 K \n",
            "5 | train_acc     | Accuracy | 0     \n",
            "6 | val_acc       | Accuracy | 0     \n",
            "7 | test_acc      | Accuracy | 0     \n",
            "-------------------------------------------\n",
            "936 K     Trainable params\n",
            "0         Non-trainable params\n",
            "936 K     Total params\n",
            "Validation sanity check: 0it [00:00, ?it/s]\n",
            "Epoch 0:  91% 430/470 [00:17<00:01, 24.71it/s, loss=0.212, v_num=0, val_loss=2.33, val_acc=0.0664]\n",
            "Epoch 0:  92% 433/470 [00:17<00:01, 24.80it/s, loss=0.212, v_num=0, val_loss=2.33, val_acc=0.0664]\n",
            "Epoch 0:  93% 438/470 [00:17<00:01, 24.91it/s, loss=0.212, v_num=0, val_loss=2.33, val_acc=0.0664]\n",
            "Validating:  20% 8/40 [00:00<00:00, 38.91it/s]\u001b[A\n",
            "Epoch 0:  94% 443/470 [00:17<00:01, 25.00it/s, loss=0.212, v_num=0, val_loss=2.33, val_acc=0.0664]\n",
            "Epoch 0:  95% 448/470 [00:17<00:00, 25.09it/s, loss=0.212, v_num=0, val_loss=2.33, val_acc=0.0664]\n",
            "Epoch 0:  96% 453/470 [00:17<00:00, 25.19it/s, loss=0.212, v_num=0, val_loss=2.33, val_acc=0.0664]\n",
            "Epoch 0:  97% 458/470 [00:18<00:00, 25.29it/s, loss=0.212, v_num=0, val_loss=2.33, val_acc=0.0664]\n",
            "Epoch 0:  99% 463/470 [00:18<00:00, 25.39it/s, loss=0.212, v_num=0, val_loss=2.33, val_acc=0.0664]\n",
            "Validating:  82% 33/40 [00:00<00:00, 38.69it/s]\u001b[A\n",
            "Epoch 0: 100% 470/470 [00:18<00:00, 25.46it/s, loss=0.212, v_num=0, val_loss=0.162, val_acc=0.953]\n",
            "Epoch 1:  91% 430/470 [00:18<00:01, 23.06it/s, loss=0.158, v_num=0, val_loss=0.162, val_acc=0.953]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 1:  93% 435/470 [00:18<00:01, 23.18it/s, loss=0.158, v_num=0, val_loss=0.162, val_acc=0.953]\n",
            "Epoch 1:  94% 440/470 [00:18<00:01, 23.28it/s, loss=0.158, v_num=0, val_loss=0.162, val_acc=0.953]\n",
            "Epoch 1:  95% 445/470 [00:19<00:01, 23.38it/s, loss=0.158, v_num=0, val_loss=0.162, val_acc=0.953]\n",
            "Epoch 1:  96% 450/470 [00:19<00:00, 23.47it/s, loss=0.158, v_num=0, val_loss=0.162, val_acc=0.953]\n",
            "Validating:  50% 20/40 [00:00<00:00, 36.52it/s]\u001b[A\n",
            "Epoch 1:  97% 455/470 [00:19<00:00, 23.56it/s, loss=0.158, v_num=0, val_loss=0.162, val_acc=0.953]\n",
            "Epoch 1:  98% 460/470 [00:19<00:00, 23.66it/s, loss=0.158, v_num=0, val_loss=0.162, val_acc=0.953]\n",
            "Epoch 1:  99% 465/470 [00:19<00:00, 23.75it/s, loss=0.158, v_num=0, val_loss=0.162, val_acc=0.953]\n",
            "Epoch 1: 100% 470/470 [00:19<00:00, 23.78it/s, loss=0.158, v_num=0, val_loss=0.12, val_acc=0.966] \n",
            "Epoch 2:  91% 430/470 [00:18<00:01, 23.00it/s, loss=0.124, v_num=0, val_loss=0.12, val_acc=0.966]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 2:  93% 436/470 [00:18<00:01, 23.16it/s, loss=0.124, v_num=0, val_loss=0.12, val_acc=0.966]\n",
            "Epoch 2:  94% 442/470 [00:18<00:01, 23.28it/s, loss=0.124, v_num=0, val_loss=0.12, val_acc=0.966]\n",
            "Validating:  32% 13/40 [00:00<00:00, 38.75it/s]\u001b[A\n",
            "Epoch 2:  95% 448/470 [00:19<00:00, 23.41it/s, loss=0.124, v_num=0, val_loss=0.12, val_acc=0.966]\n",
            "Epoch 2:  97% 454/470 [00:19<00:00, 23.53it/s, loss=0.124, v_num=0, val_loss=0.12, val_acc=0.966]\n",
            "Validating:  62% 25/40 [00:00<00:00, 38.54it/s]\u001b[A\n",
            "Epoch 2:  98% 460/470 [00:19<00:00, 23.64it/s, loss=0.124, v_num=0, val_loss=0.12, val_acc=0.966]\n",
            "Epoch 2:  99% 466/470 [00:19<00:00, 23.76it/s, loss=0.124, v_num=0, val_loss=0.12, val_acc=0.966]\n",
            "Epoch 2: 100% 470/470 [00:19<00:00, 23.80it/s, loss=0.124, v_num=0, val_loss=0.108, val_acc=0.969]\n",
            "Epoch 2: 100% 470/470 [00:19<00:00, 23.77it/s, loss=0.124, v_num=0, val_loss=0.108, val_acc=0.969]\n",
            "Testing: 100% 79/79 [00:01<00:00, 39.67it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': tensor(0.9730)}\n",
            "--------------------------------------------------------------------------------\n",
            "9920512it [01:49, 90749.43it/s] \n",
            "1654784it [01:09, 23835.87it/s] \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxjM3aFuvF7F",
        "outputId": "fdfc980a-fc71-4480-87e8-90591a583f84"
      },
      "source": [
        "ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "readme.md  \u001b[0m\u001b[01;34mtext_recognizer\u001b[0m/  \u001b[01;34mtraining\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "e8HJoiFlvtuV",
        "outputId": "8559a240-e432-4805-a846-f0eea950c457"
      },
      "source": [
        "pwd"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/fsdl-text-recognizer-2021-labs/lab1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5Rsff4mvyEG",
        "outputId": "fb0ae567-51eb-4e54-cd51-5ab312d2640f"
      },
      "source": [
        "!git pull"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJEuCADQxcYz",
        "outputId": "6c1a35a1-0133-416f-9d53-07a69727c86c"
      },
      "source": [
        "!python3 training/run_experiment.py --model_class=MLP --data_class=MNIST --fc1=128 --fc2=64"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: You have set progress_bar_refresh_rate < 20 on Google Colab. This may crash. Consider using progress_bar_refresh_rate >= 20 in Trainer.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "GPU available: True, used: False\n",
            "TPU available: None, using: 0 TPU cores\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: GPU available but not used. Set the --gpus flag when calling the script.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "2021-07-26 00:08:58.034342: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "\n",
            "  | Name          | Type     | Params\n",
            "-------------------------------------------\n",
            "0 | model         | MLP      | 109 K \n",
            "1 | model.dropout | Dropout  | 0     \n",
            "2 | model.fc1     | Linear   | 100 K \n",
            "3 | model.fc2     | Linear   | 8.3 K \n",
            "4 | model.fc3     | Linear   | 650   \n",
            "5 | train_acc     | Accuracy | 0     \n",
            "6 | val_acc       | Accuracy | 0     \n",
            "7 | test_acc      | Accuracy | 0     \n",
            "-------------------------------------------\n",
            "109 K     Trainable params\n",
            "0         Non-trainable params\n",
            "109 K     Total params\n",
            "Epoch 0:  91% 430/470 [00:11<00:01, 38.64it/s, loss=0.402, v_num=1, val_loss=2.31, val_acc=0.145]\n",
            "Epoch 0:  93% 435/470 [00:11<00:00, 38.78it/s, loss=0.402, v_num=1, val_loss=2.31, val_acc=0.145]\n",
            "Validating:  12% 5/40 [00:00<00:00, 45.38it/s]\u001b[A\n",
            "Epoch 0:  94% 442/470 [00:11<00:00, 38.88it/s, loss=0.402, v_num=1, val_loss=2.31, val_acc=0.145]\n",
            "Epoch 0:  96% 449/470 [00:11<00:00, 38.95it/s, loss=0.402, v_num=1, val_loss=2.31, val_acc=0.145]\n",
            "Validating:  50% 20/40 [00:00<00:00, 44.82it/s]\u001b[A\n",
            "Epoch 0:  97% 456/470 [00:11<00:00, 39.01it/s, loss=0.402, v_num=1, val_loss=2.31, val_acc=0.145]\n",
            "Epoch 0:  99% 463/470 [00:11<00:00, 39.07it/s, loss=0.402, v_num=1, val_loss=2.31, val_acc=0.145]\n",
            "Epoch 0: 100% 470/470 [00:12<00:00, 39.10it/s, loss=0.402, v_num=1, val_loss=0.237, val_acc=0.933]\n",
            "Epoch 1:  91% 430/470 [00:11<00:01, 37.18it/s, loss=0.312, v_num=1, val_loss=0.237, val_acc=0.933]\n",
            "Epoch 1:  92% 434/470 [00:11<00:00, 37.29it/s, loss=0.312, v_num=1, val_loss=0.237, val_acc=0.933]\n",
            "Validating:  10% 4/40 [00:00<00:00, 38.59it/s]\u001b[A\n",
            "Epoch 1:  94% 441/470 [00:11<00:00, 37.33it/s, loss=0.312, v_num=1, val_loss=0.237, val_acc=0.933]\n",
            "Epoch 1:  95% 448/470 [00:11<00:00, 37.40it/s, loss=0.312, v_num=1, val_loss=0.237, val_acc=0.933]\n",
            "Validating:  48% 19/40 [00:00<00:00, 40.97it/s]\u001b[A\n",
            "Epoch 1:  97% 455/470 [00:12<00:00, 37.49it/s, loss=0.312, v_num=1, val_loss=0.237, val_acc=0.933]\n",
            "Epoch 1:  98% 462/470 [00:12<00:00, 37.54it/s, loss=0.312, v_num=1, val_loss=0.237, val_acc=0.933]\n",
            "Validating:  85% 34/40 [00:00<00:00, 41.26it/s]\u001b[A\n",
            "Epoch 1: 100% 470/470 [00:12<00:00, 37.54it/s, loss=0.312, v_num=1, val_loss=0.173, val_acc=0.949]\n",
            "Epoch 2:  91% 430/470 [00:12<00:01, 35.67it/s, loss=0.271, v_num=1, val_loss=0.173, val_acc=0.949]\n",
            "Epoch 2:  92% 434/470 [00:12<00:01, 35.77it/s, loss=0.271, v_num=1, val_loss=0.173, val_acc=0.949]\n",
            "Validating:  10% 4/40 [00:00<00:00, 39.45it/s]\u001b[A\n",
            "Epoch 2:  94% 441/470 [00:12<00:00, 35.80it/s, loss=0.271, v_num=1, val_loss=0.173, val_acc=0.949]\n",
            "Validating:  30% 12/40 [00:00<00:00, 38.50it/s]\u001b[A\n",
            "Epoch 2:  95% 448/470 [00:12<00:00, 35.88it/s, loss=0.271, v_num=1, val_loss=0.173, val_acc=0.949]\n",
            "Epoch 2:  97% 455/470 [00:12<00:00, 35.97it/s, loss=0.271, v_num=1, val_loss=0.173, val_acc=0.949]\n",
            "Epoch 2:  98% 462/470 [00:12<00:00, 36.04it/s, loss=0.271, v_num=1, val_loss=0.173, val_acc=0.949]\n",
            "Validating:  80% 32/40 [00:00<00:00, 41.36it/s]\u001b[A\n",
            "Epoch 2: 100% 470/470 [00:13<00:00, 36.11it/s, loss=0.271, v_num=1, val_loss=0.162, val_acc=0.951]\n",
            "Epoch 3:  91% 430/470 [00:11<00:01, 36.53it/s, loss=0.287, v_num=1, val_loss=0.162, val_acc=0.951]\n",
            "Epoch 3:  92% 434/470 [00:11<00:00, 36.66it/s, loss=0.287, v_num=1, val_loss=0.162, val_acc=0.951]\n",
            "Validating:  12% 5/40 [00:00<00:00, 44.96it/s]\u001b[A\n",
            "Epoch 3:  94% 441/470 [00:11<00:00, 36.77it/s, loss=0.287, v_num=1, val_loss=0.162, val_acc=0.951]\n",
            "Epoch 3:  95% 448/470 [00:12<00:00, 36.88it/s, loss=0.287, v_num=1, val_loss=0.162, val_acc=0.951]\n",
            "Epoch 3:  97% 455/470 [00:12<00:00, 36.97it/s, loss=0.287, v_num=1, val_loss=0.162, val_acc=0.951]\n",
            "Validating:  62% 25/40 [00:00<00:00, 44.79it/s]\u001b[A\n",
            "Epoch 3:  98% 462/470 [00:12<00:00, 37.03it/s, loss=0.287, v_num=1, val_loss=0.162, val_acc=0.951]\n",
            "Epoch 3: 100% 470/470 [00:12<00:00, 37.10it/s, loss=0.287, v_num=1, val_loss=0.138, val_acc=0.961]\n",
            "Epoch 4:  91% 430/470 [00:11<00:01, 37.36it/s, loss=0.246, v_num=1, val_loss=0.138, val_acc=0.961]\n",
            "Epoch 4:  92% 434/470 [00:11<00:00, 37.48it/s, loss=0.246, v_num=1, val_loss=0.138, val_acc=0.961]\n",
            "Validating:  12% 5/40 [00:00<00:00, 43.86it/s]\u001b[A\n",
            "Epoch 4:  94% 441/470 [00:11<00:00, 37.58it/s, loss=0.246, v_num=1, val_loss=0.138, val_acc=0.961]\n",
            "Epoch 4:  95% 448/470 [00:11<00:00, 37.67it/s, loss=0.246, v_num=1, val_loss=0.138, val_acc=0.961]\n",
            "Epoch 4:  97% 455/470 [00:12<00:00, 37.76it/s, loss=0.246, v_num=1, val_loss=0.138, val_acc=0.961]\n",
            "Validating:  62% 25/40 [00:00<00:00, 44.85it/s]\u001b[A\n",
            "Epoch 4:  98% 462/470 [00:12<00:00, 37.82it/s, loss=0.246, v_num=1, val_loss=0.138, val_acc=0.961]\n",
            "Epoch 4: 100% 470/470 [00:12<00:00, 37.89it/s, loss=0.246, v_num=1, val_loss=0.128, val_acc=0.966]\n",
            "Epoch 5:  91% 430/470 [00:11<00:01, 37.26it/s, loss=0.22, v_num=1, val_loss=0.128, val_acc=0.966] \n",
            "Epoch 5:  92% 434/470 [00:11<00:00, 37.37it/s, loss=0.22, v_num=1, val_loss=0.128, val_acc=0.966]\n",
            "Validating:  12% 5/40 [00:00<00:00, 41.59it/s]\u001b[A\n",
            "Epoch 5:  94% 441/470 [00:11<00:00, 37.45it/s, loss=0.22, v_num=1, val_loss=0.128, val_acc=0.966]\n",
            "Epoch 5:  95% 448/470 [00:11<00:00, 37.53it/s, loss=0.22, v_num=1, val_loss=0.128, val_acc=0.966]\n",
            "Epoch 5:  97% 455/470 [00:12<00:00, 37.59it/s, loss=0.22, v_num=1, val_loss=0.128, val_acc=0.966]\n",
            "Validating:  62% 25/40 [00:00<00:00, 42.64it/s]\u001b[A\n",
            "Epoch 5:  98% 462/470 [00:12<00:00, 37.68it/s, loss=0.22, v_num=1, val_loss=0.128, val_acc=0.966]\n",
            "Epoch 5: 100% 470/470 [00:12<00:00, 37.77it/s, loss=0.22, v_num=1, val_loss=0.12, val_acc=0.966] \n",
            "Epoch 6:  91% 430/470 [00:11<00:01, 36.64it/s, loss=0.232, v_num=1, val_loss=0.12, val_acc=0.966]\n",
            "Epoch 6:  92% 434/470 [00:11<00:00, 36.74it/s, loss=0.232, v_num=1, val_loss=0.12, val_acc=0.966]\n",
            "Validating:  12% 5/40 [00:00<00:00, 40.54it/s]\u001b[A\n",
            "Epoch 6:  94% 441/470 [00:11<00:00, 36.82it/s, loss=0.232, v_num=1, val_loss=0.12, val_acc=0.966]\n",
            "Epoch 6:  95% 448/470 [00:12<00:00, 36.88it/s, loss=0.232, v_num=1, val_loss=0.12, val_acc=0.966]\n",
            "Epoch 6:  97% 455/470 [00:12<00:00, 36.96it/s, loss=0.232, v_num=1, val_loss=0.12, val_acc=0.966]\n",
            "Validating:  62% 25/40 [00:00<00:00, 41.83it/s]\u001b[A\n",
            "Epoch 6:  98% 462/470 [00:12<00:00, 36.99it/s, loss=0.232, v_num=1, val_loss=0.12, val_acc=0.966]\n",
            "Epoch 6: 100% 469/470 [00:12<00:00, 37.06it/s, loss=0.232, v_num=1, val_loss=0.12, val_acc=0.966]\n",
            "Epoch 6: 100% 470/470 [00:12<00:00, 37.03it/s, loss=0.232, v_num=1, val_loss=0.119, val_acc=0.969]\n",
            "Epoch 7:  91% 430/470 [00:12<00:01, 35.47it/s, loss=0.216, v_num=1, val_loss=0.119, val_acc=0.969]\n",
            "Epoch 7:  92% 434/470 [00:12<00:01, 35.60it/s, loss=0.216, v_num=1, val_loss=0.119, val_acc=0.969]\n",
            "Validating:  12% 5/40 [00:00<00:00, 43.97it/s]\u001b[A\n",
            "Epoch 7:  94% 441/470 [00:12<00:00, 35.66it/s, loss=0.216, v_num=1, val_loss=0.119, val_acc=0.969]\n",
            "Epoch 7:  95% 448/470 [00:12<00:00, 35.74it/s, loss=0.216, v_num=1, val_loss=0.119, val_acc=0.969]\n",
            "Validating:  45% 18/40 [00:00<00:00, 42.02it/s]\u001b[A\n",
            "Epoch 7:  97% 455/470 [00:12<00:00, 35.80it/s, loss=0.216, v_num=1, val_loss=0.119, val_acc=0.969]\n",
            "Epoch 7:  98% 462/470 [00:12<00:00, 35.88it/s, loss=0.216, v_num=1, val_loss=0.119, val_acc=0.969]\n",
            "Validating:  80% 32/40 [00:00<00:00, 40.89it/s]\u001b[A\n",
            "Epoch 7: 100% 470/470 [00:13<00:00, 35.91it/s, loss=0.216, v_num=1, val_loss=0.114, val_acc=0.967]\n",
            "Epoch 8:  91% 430/470 [00:11<00:01, 36.09it/s, loss=0.233, v_num=1, val_loss=0.114, val_acc=0.967]\n",
            "Epoch 8:  92% 434/470 [00:11<00:00, 36.18it/s, loss=0.233, v_num=1, val_loss=0.114, val_acc=0.967]\n",
            "Validating:  10% 4/40 [00:00<00:00, 39.82it/s]\u001b[A\n",
            "Epoch 8:  94% 441/470 [00:12<00:00, 36.30it/s, loss=0.233, v_num=1, val_loss=0.114, val_acc=0.967]\n",
            "Epoch 8:  95% 448/470 [00:12<00:00, 36.41it/s, loss=0.233, v_num=1, val_loss=0.114, val_acc=0.967]\n",
            "Validating:  48% 19/40 [00:00<00:00, 43.25it/s]\u001b[A\n",
            "Epoch 8:  97% 455/470 [00:12<00:00, 36.51it/s, loss=0.233, v_num=1, val_loss=0.114, val_acc=0.967]\n",
            "Epoch 8:  98% 462/470 [00:12<00:00, 36.62it/s, loss=0.233, v_num=1, val_loss=0.114, val_acc=0.967]\n",
            "Epoch 8: 100% 469/470 [00:12<00:00, 36.72it/s, loss=0.233, v_num=1, val_loss=0.114, val_acc=0.967]\n",
            "Epoch 8: 100% 470/470 [00:12<00:00, 36.71it/s, loss=0.233, v_num=1, val_loss=0.109, val_acc=0.969]\n",
            "Epoch 9:  91% 430/470 [00:11<00:01, 35.89it/s, loss=0.22, v_num=1, val_loss=0.109, val_acc=0.969] \n",
            "Epoch 9:  92% 434/470 [00:12<00:00, 36.01it/s, loss=0.22, v_num=1, val_loss=0.109, val_acc=0.969]\n",
            "Validating:  12% 5/40 [00:00<00:00, 41.15it/s]\u001b[A\n",
            "Epoch 9:  94% 441/470 [00:12<00:00, 36.04it/s, loss=0.22, v_num=1, val_loss=0.109, val_acc=0.969]\n",
            "Validating:  32% 13/40 [00:00<00:00, 38.93it/s]\u001b[A\n",
            "Epoch 9:  95% 448/470 [00:12<00:00, 36.04it/s, loss=0.22, v_num=1, val_loss=0.109, val_acc=0.969]\n",
            "Epoch 9:  97% 455/470 [00:12<00:00, 36.08it/s, loss=0.22, v_num=1, val_loss=0.109, val_acc=0.969]\n",
            "Validating:  62% 25/40 [00:00<00:00, 38.27it/s]\u001b[A\n",
            "Epoch 9:  98% 462/470 [00:12<00:00, 36.15it/s, loss=0.22, v_num=1, val_loss=0.109, val_acc=0.969]\n",
            "Epoch 9: 100% 469/470 [00:12<00:00, 36.23it/s, loss=0.22, v_num=1, val_loss=0.109, val_acc=0.969]\n",
            "Epoch 9: 100% 470/470 [00:12<00:00, 36.21it/s, loss=0.22, v_num=1, val_loss=0.107, val_acc=0.971]\n",
            "Epoch 10:  91% 430/470 [00:12<00:01, 35.38it/s, loss=0.183, v_num=1, val_loss=0.107, val_acc=0.971]\n",
            "Epoch 10:  92% 434/470 [00:12<00:01, 35.49it/s, loss=0.183, v_num=1, val_loss=0.107, val_acc=0.971]\n",
            "Validating:  12% 5/40 [00:00<00:00, 41.76it/s]\u001b[A\n",
            "Epoch 10:  94% 441/470 [00:12<00:00, 35.58it/s, loss=0.183, v_num=1, val_loss=0.107, val_acc=0.971]\n",
            "Epoch 10:  95% 448/470 [00:12<00:00, 35.65it/s, loss=0.183, v_num=1, val_loss=0.107, val_acc=0.971]\n",
            "Epoch 10:  97% 455/470 [00:12<00:00, 35.74it/s, loss=0.183, v_num=1, val_loss=0.107, val_acc=0.971]\n",
            "Validating:  62% 25/40 [00:00<00:00, 41.94it/s]\u001b[A\n",
            "Epoch 10:  98% 462/470 [00:12<00:00, 35.83it/s, loss=0.183, v_num=1, val_loss=0.107, val_acc=0.971]\n",
            "Epoch 10: 100% 470/470 [00:13<00:00, 35.89it/s, loss=0.183, v_num=1, val_loss=0.107, val_acc=0.971]\n",
            "Epoch 11:  91% 430/470 [00:11<00:01, 37.53it/s, loss=0.177, v_num=1, val_loss=0.107, val_acc=0.971]\n",
            "Epoch 11:  92% 434/470 [00:11<00:00, 37.66it/s, loss=0.177, v_num=1, val_loss=0.107, val_acc=0.971]\n",
            "Validating:  12% 5/40 [00:00<00:00, 45.54it/s]\u001b[A\n",
            "Epoch 11:  94% 441/470 [00:11<00:00, 37.71it/s, loss=0.177, v_num=1, val_loss=0.107, val_acc=0.971]\n",
            "Epoch 11:  95% 448/470 [00:11<00:00, 37.79it/s, loss=0.177, v_num=1, val_loss=0.107, val_acc=0.971]\n",
            "Validating:  48% 19/40 [00:00<00:00, 43.88it/s]\u001b[A\n",
            "Epoch 11:  97% 455/470 [00:12<00:00, 37.87it/s, loss=0.177, v_num=1, val_loss=0.107, val_acc=0.971]\n",
            "Epoch 11:  98% 462/470 [00:12<00:00, 37.92it/s, loss=0.177, v_num=1, val_loss=0.107, val_acc=0.971]\n",
            "Epoch 11: 100% 469/470 [00:12<00:00, 38.00it/s, loss=0.177, v_num=1, val_loss=0.107, val_acc=0.971]\n",
            "Epoch 11: 100% 470/470 [00:12<00:00, 37.99it/s, loss=0.177, v_num=1, val_loss=0.1, val_acc=0.97]   \n",
            "Epoch 12:  91% 430/470 [00:11<00:01, 37.63it/s, loss=0.214, v_num=1, val_loss=0.1, val_acc=0.97]\n",
            "Epoch 12:  92% 434/470 [00:11<00:00, 37.75it/s, loss=0.214, v_num=1, val_loss=0.1, val_acc=0.97]\n",
            "Validating:  12% 5/40 [00:00<00:00, 45.24it/s]\u001b[A\n",
            "Epoch 12:  94% 441/470 [00:11<00:00, 37.85it/s, loss=0.214, v_num=1, val_loss=0.1, val_acc=0.97]\n",
            "Epoch 12:  95% 448/470 [00:11<00:00, 37.95it/s, loss=0.214, v_num=1, val_loss=0.1, val_acc=0.97]\n",
            "Epoch 12:  97% 455/470 [00:11<00:00, 38.04it/s, loss=0.214, v_num=1, val_loss=0.1, val_acc=0.97]\n",
            "Validating:  62% 25/40 [00:00<00:00, 45.03it/s]\u001b[A\n",
            "Epoch 12:  98% 462/470 [00:12<00:00, 38.13it/s, loss=0.214, v_num=1, val_loss=0.1, val_acc=0.97]\n",
            "Epoch 12: 100% 470/470 [00:12<00:00, 38.19it/s, loss=0.214, v_num=1, val_loss=0.099, val_acc=0.973]\n",
            "Epoch 13:  91% 430/470 [00:11<00:01, 38.03it/s, loss=0.189, v_num=1, val_loss=0.099, val_acc=0.973]\n",
            "Epoch 13:  92% 434/470 [00:11<00:00, 38.14it/s, loss=0.189, v_num=1, val_loss=0.099, val_acc=0.973]\n",
            "Validating:  12% 5/40 [00:00<00:00, 43.83it/s]\u001b[A\n",
            "Epoch 13:  94% 441/470 [00:11<00:00, 38.24it/s, loss=0.189, v_num=1, val_loss=0.099, val_acc=0.973]\n",
            "Epoch 13:  95% 448/470 [00:11<00:00, 38.34it/s, loss=0.189, v_num=1, val_loss=0.099, val_acc=0.973]\n",
            "Epoch 13:  97% 455/470 [00:11<00:00, 38.44it/s, loss=0.189, v_num=1, val_loss=0.099, val_acc=0.973]\n",
            "Validating:  62% 25/40 [00:00<00:00, 45.39it/s]\u001b[A\n",
            "Epoch 13:  98% 462/470 [00:11<00:00, 38.52it/s, loss=0.189, v_num=1, val_loss=0.099, val_acc=0.973]\n",
            "Epoch 13: 100% 470/470 [00:12<00:00, 38.60it/s, loss=0.189, v_num=1, val_loss=0.1, val_acc=0.973]  \n",
            "Epoch 14:  91% 430/470 [00:11<00:01, 37.02it/s, loss=0.174, v_num=1, val_loss=0.1, val_acc=0.973]\n",
            "Epoch 14:  92% 434/470 [00:11<00:00, 37.13it/s, loss=0.174, v_num=1, val_loss=0.1, val_acc=0.973]\n",
            "Validating:  12% 5/40 [00:00<00:00, 41.90it/s]\u001b[A\n",
            "Epoch 14:  94% 441/470 [00:11<00:00, 37.20it/s, loss=0.174, v_num=1, val_loss=0.1, val_acc=0.973]\n",
            "Epoch 14:  95% 448/470 [00:12<00:00, 37.28it/s, loss=0.174, v_num=1, val_loss=0.1, val_acc=0.973]\n",
            "Epoch 14:  97% 455/470 [00:12<00:00, 37.35it/s, loss=0.174, v_num=1, val_loss=0.1, val_acc=0.973]\n",
            "Validating:  62% 25/40 [00:00<00:00, 42.31it/s]\u001b[A\n",
            "Epoch 14:  98% 462/470 [00:12<00:00, 37.39it/s, loss=0.174, v_num=1, val_loss=0.1, val_acc=0.973]\n",
            "Epoch 14: 100% 469/470 [00:12<00:00, 37.47it/s, loss=0.174, v_num=1, val_loss=0.1, val_acc=0.973]\n",
            "Epoch 14: 100% 470/470 [00:12<00:00, 37.47it/s, loss=0.174, v_num=1, val_loss=0.0992, val_acc=0.971]\n",
            "Epoch 15:  91% 430/470 [00:11<00:01, 36.05it/s, loss=0.18, v_num=1, val_loss=0.0992, val_acc=0.971] \n",
            "Epoch 15:  92% 434/470 [00:11<00:00, 36.17it/s, loss=0.18, v_num=1, val_loss=0.0992, val_acc=0.971]\n",
            "Validating:  12% 5/40 [00:00<00:00, 42.01it/s]\u001b[A\n",
            "Epoch 15:  94% 441/470 [00:12<00:00, 36.25it/s, loss=0.18, v_num=1, val_loss=0.0992, val_acc=0.971]\n",
            "Epoch 15:  95% 448/470 [00:12<00:00, 36.33it/s, loss=0.18, v_num=1, val_loss=0.0992, val_acc=0.971]\n",
            "Epoch 15:  97% 455/470 [00:12<00:00, 36.41it/s, loss=0.18, v_num=1, val_loss=0.0992, val_acc=0.971]\n",
            "Validating:  62% 25/40 [00:00<00:00, 42.48it/s]\u001b[A\n",
            "Epoch 15:  98% 462/470 [00:12<00:00, 36.49it/s, loss=0.18, v_num=1, val_loss=0.0992, val_acc=0.971]\n",
            "Epoch 15: 100% 469/470 [00:12<00:00, 36.56it/s, loss=0.18, v_num=1, val_loss=0.0992, val_acc=0.971]\n",
            "Epoch 15: 100% 470/470 [00:12<00:00, 36.53it/s, loss=0.18, v_num=1, val_loss=0.103, val_acc=0.971] \n",
            "Epoch 16:  91% 430/470 [00:11<00:01, 36.90it/s, loss=0.184, v_num=1, val_loss=0.103, val_acc=0.971]\n",
            "Epoch 16:  92% 434/470 [00:11<00:00, 37.03it/s, loss=0.184, v_num=1, val_loss=0.103, val_acc=0.971]\n",
            "Validating:  12% 5/40 [00:00<00:00, 46.57it/s]\u001b[A\n",
            "Epoch 16:  94% 441/470 [00:11<00:00, 37.13it/s, loss=0.184, v_num=1, val_loss=0.103, val_acc=0.971]\n",
            "Epoch 16:  95% 448/470 [00:12<00:00, 37.25it/s, loss=0.184, v_num=1, val_loss=0.103, val_acc=0.971]\n",
            "Validating:  50% 20/40 [00:00<00:00, 46.32it/s]\u001b[A\n",
            "Epoch 16:  97% 455/470 [00:12<00:00, 37.30it/s, loss=0.184, v_num=1, val_loss=0.103, val_acc=0.971]\n",
            "Epoch 16:  98% 462/470 [00:12<00:00, 37.41it/s, loss=0.184, v_num=1, val_loss=0.103, val_acc=0.971]\n",
            "Epoch 16: 100% 469/470 [00:12<00:00, 37.49it/s, loss=0.184, v_num=1, val_loss=0.103, val_acc=0.971]\n",
            "Epoch 16: 100% 470/470 [00:12<00:00, 37.48it/s, loss=0.184, v_num=1, val_loss=0.0966, val_acc=0.974]\n",
            "Epoch 17:  91% 430/470 [00:11<00:01, 38.06it/s, loss=0.192, v_num=1, val_loss=0.0966, val_acc=0.974]\n",
            "Epoch 17:  92% 434/470 [00:11<00:00, 38.20it/s, loss=0.192, v_num=1, val_loss=0.0966, val_acc=0.974]\n",
            "Validating:  12% 5/40 [00:00<00:00, 47.49it/s]\u001b[A\n",
            "Epoch 17:  94% 441/470 [00:11<00:00, 38.28it/s, loss=0.192, v_num=1, val_loss=0.0966, val_acc=0.974]\n",
            "Epoch 17:  95% 448/470 [00:11<00:00, 38.37it/s, loss=0.192, v_num=1, val_loss=0.0966, val_acc=0.974]\n",
            "Epoch 17:  97% 455/470 [00:11<00:00, 38.44it/s, loss=0.192, v_num=1, val_loss=0.0966, val_acc=0.974]\n",
            "Validating:  62% 25/40 [00:00<00:00, 44.79it/s]\u001b[A\n",
            "Epoch 17:  98% 462/470 [00:11<00:00, 38.51it/s, loss=0.192, v_num=1, val_loss=0.0966, val_acc=0.974]\n",
            "Epoch 17: 100% 470/470 [00:12<00:00, 38.57it/s, loss=0.192, v_num=1, val_loss=0.0958, val_acc=0.974]\n",
            "Epoch 18:  91% 430/470 [00:11<00:01, 37.78it/s, loss=0.154, v_num=1, val_loss=0.0958, val_acc=0.974]\n",
            "Epoch 18:  92% 434/470 [00:11<00:00, 37.89it/s, loss=0.154, v_num=1, val_loss=0.0958, val_acc=0.974]\n",
            "Validating:  12% 5/40 [00:00<00:00, 43.56it/s]\u001b[A\n",
            "Epoch 18:  94% 441/470 [00:11<00:00, 37.98it/s, loss=0.154, v_num=1, val_loss=0.0958, val_acc=0.974]\n",
            "Epoch 18:  95% 448/470 [00:11<00:00, 38.07it/s, loss=0.154, v_num=1, val_loss=0.0958, val_acc=0.974]\n",
            "Epoch 18:  97% 455/470 [00:11<00:00, 38.16it/s, loss=0.154, v_num=1, val_loss=0.0958, val_acc=0.974]\n",
            "Validating:  62% 25/40 [00:00<00:00, 44.61it/s]\u001b[A\n",
            "Epoch 18:  98% 462/470 [00:12<00:00, 38.26it/s, loss=0.154, v_num=1, val_loss=0.0958, val_acc=0.974]\n",
            "Epoch 18: 100% 470/470 [00:12<00:00, 38.34it/s, loss=0.154, v_num=1, val_loss=0.0966, val_acc=0.974]\n",
            "Epoch 19:  91% 430/470 [00:11<00:01, 37.44it/s, loss=0.16, v_num=1, val_loss=0.0966, val_acc=0.974] \n",
            "Epoch 19:  92% 434/470 [00:11<00:00, 37.55it/s, loss=0.16, v_num=1, val_loss=0.0966, val_acc=0.974]\n",
            "Validating:  12% 5/40 [00:00<00:00, 39.04it/s]\u001b[A\n",
            "Epoch 19:  94% 441/470 [00:11<00:00, 37.59it/s, loss=0.16, v_num=1, val_loss=0.0966, val_acc=0.974]\n",
            "Epoch 19:  95% 448/470 [00:11<00:00, 37.61it/s, loss=0.16, v_num=1, val_loss=0.0966, val_acc=0.974]\n",
            "Validating:  45% 18/40 [00:00<00:00, 39.03it/s]\u001b[A\n",
            "Epoch 19:  97% 455/470 [00:12<00:00, 37.63it/s, loss=0.16, v_num=1, val_loss=0.0966, val_acc=0.974]\n",
            "Epoch 19:  98% 462/470 [00:12<00:00, 37.70it/s, loss=0.16, v_num=1, val_loss=0.0966, val_acc=0.974]\n",
            "Validating:  82% 33/40 [00:00<00:00, 41.16it/s]\u001b[A\n",
            "Epoch 19: 100% 470/470 [00:12<00:00, 37.73it/s, loss=0.16, v_num=1, val_loss=0.101, val_acc=0.972] \n",
            "Epoch 20:  91% 430/470 [00:12<00:01, 34.94it/s, loss=0.149, v_num=1, val_loss=0.101, val_acc=0.972]\n",
            "Epoch 20:  92% 434/470 [00:12<00:01, 35.05it/s, loss=0.149, v_num=1, val_loss=0.101, val_acc=0.972]\n",
            "Validating:  10% 4/40 [00:00<00:00, 39.88it/s]\u001b[A\n",
            "Epoch 20:  94% 441/470 [00:12<00:00, 35.13it/s, loss=0.149, v_num=1, val_loss=0.101, val_acc=0.972]\n",
            "Epoch 20:  95% 448/470 [00:12<00:00, 35.20it/s, loss=0.149, v_num=1, val_loss=0.101, val_acc=0.972]\n",
            "Validating:  48% 19/40 [00:00<00:00, 40.71it/s]\u001b[A\n",
            "Epoch 20:  97% 455/470 [00:12<00:00, 35.28it/s, loss=0.149, v_num=1, val_loss=0.101, val_acc=0.972]\n",
            "Epoch 20:  98% 462/470 [00:13<00:00, 35.37it/s, loss=0.149, v_num=1, val_loss=0.101, val_acc=0.972]\n",
            "Validating:  82% 33/40 [00:00<00:00, 40.91it/s]\u001b[A\n",
            "Epoch 20: 100% 470/470 [00:13<00:00, 35.44it/s, loss=0.149, v_num=1, val_loss=0.0979, val_acc=0.972]\n",
            "Epoch 21:  91% 430/470 [00:11<00:01, 35.89it/s, loss=0.143, v_num=1, val_loss=0.0979, val_acc=0.972]\n",
            "Epoch 21:  92% 434/470 [00:12<00:00, 36.03it/s, loss=0.143, v_num=1, val_loss=0.0979, val_acc=0.972]\n",
            "Validating:  12% 5/40 [00:00<00:00, 44.71it/s]\u001b[A\n",
            "Epoch 21:  94% 441/470 [00:12<00:00, 36.14it/s, loss=0.143, v_num=1, val_loss=0.0979, val_acc=0.972]\n",
            "Epoch 21:  95% 448/470 [00:12<00:00, 36.24it/s, loss=0.143, v_num=1, val_loss=0.0979, val_acc=0.972]\n",
            "Epoch 21:  97% 455/470 [00:12<00:00, 36.34it/s, loss=0.143, v_num=1, val_loss=0.0979, val_acc=0.972]\n",
            "Validating:  62% 25/40 [00:00<00:00, 43.57it/s]\u001b[A\n",
            "Epoch 21:  98% 462/470 [00:12<00:00, 36.40it/s, loss=0.143, v_num=1, val_loss=0.0979, val_acc=0.972]\n",
            "Epoch 21: 100% 470/470 [00:12<00:00, 36.50it/s, loss=0.143, v_num=1, val_loss=0.0907, val_acc=0.975]\n",
            "Epoch 22:  91% 430/470 [00:11<00:01, 37.58it/s, loss=0.18, v_num=1, val_loss=0.0907, val_acc=0.975] \n",
            "Epoch 22:  92% 434/470 [00:11<00:00, 37.69it/s, loss=0.18, v_num=1, val_loss=0.0907, val_acc=0.975]\n",
            "Validating:  12% 5/40 [00:00<00:00, 43.79it/s]\u001b[A\n",
            "Epoch 22:  94% 441/470 [00:11<00:00, 37.78it/s, loss=0.18, v_num=1, val_loss=0.0907, val_acc=0.975]\n",
            "Epoch 22:  95% 448/470 [00:11<00:00, 37.87it/s, loss=0.18, v_num=1, val_loss=0.0907, val_acc=0.975]\n",
            "Epoch 22:  97% 455/470 [00:11<00:00, 37.96it/s, loss=0.18, v_num=1, val_loss=0.0907, val_acc=0.975]\n",
            "Validating:  62% 25/40 [00:00<00:00, 44.18it/s]\u001b[A\n",
            "Epoch 22:  98% 462/470 [00:12<00:00, 38.05it/s, loss=0.18, v_num=1, val_loss=0.0907, val_acc=0.975]\n",
            "Epoch 22: 100% 469/470 [00:12<00:00, 38.11it/s, loss=0.18, v_num=1, val_loss=0.0907, val_acc=0.975]\n",
            "Epoch 22: 100% 470/470 [00:12<00:00, 38.10it/s, loss=0.18, v_num=1, val_loss=0.0977, val_acc=0.974]\n",
            "Epoch 23:  91% 430/470 [00:11<00:01, 38.15it/s, loss=0.156, v_num=1, val_loss=0.0977, val_acc=0.974]\n",
            "Epoch 23:  92% 434/470 [00:11<00:00, 38.24it/s, loss=0.156, v_num=1, val_loss=0.0977, val_acc=0.974]\n",
            "Validating:  12% 5/40 [00:00<00:00, 41.72it/s]\u001b[A\n",
            "Epoch 23:  94% 441/470 [00:11<00:00, 38.35it/s, loss=0.156, v_num=1, val_loss=0.0977, val_acc=0.974]\n",
            "Epoch 23:  95% 448/470 [00:11<00:00, 38.45it/s, loss=0.156, v_num=1, val_loss=0.0977, val_acc=0.974]\n",
            "Epoch 23:  97% 455/470 [00:11<00:00, 38.51it/s, loss=0.156, v_num=1, val_loss=0.0977, val_acc=0.974]\n",
            "Validating:  62% 25/40 [00:00<00:00, 43.94it/s]\u001b[A\n",
            "Epoch 23:  98% 462/470 [00:11<00:00, 38.60it/s, loss=0.156, v_num=1, val_loss=0.0977, val_acc=0.974]\n",
            "Epoch 23: 100% 470/470 [00:12<00:00, 38.70it/s, loss=0.156, v_num=1, val_loss=0.097, val_acc=0.973] \n",
            "Epoch 24:  91% 430/470 [00:11<00:01, 38.08it/s, loss=0.146, v_num=1, val_loss=0.097, val_acc=0.973]\n",
            "Epoch 24:  92% 434/470 [00:11<00:00, 38.19it/s, loss=0.146, v_num=1, val_loss=0.097, val_acc=0.973]\n",
            "Validating:  12% 5/40 [00:00<00:00, 41.14it/s]\u001b[A\n",
            "Epoch 24:  94% 441/470 [00:11<00:00, 38.27it/s, loss=0.146, v_num=1, val_loss=0.097, val_acc=0.973]\n",
            "Epoch 24:  95% 448/470 [00:11<00:00, 38.37it/s, loss=0.146, v_num=1, val_loss=0.097, val_acc=0.973]\n",
            "Epoch 24:  97% 455/470 [00:11<00:00, 38.43it/s, loss=0.146, v_num=1, val_loss=0.097, val_acc=0.973]\n",
            "Validating:  62% 25/40 [00:00<00:00, 43.70it/s]\u001b[A\n",
            "Epoch 24:  98% 462/470 [00:11<00:00, 38.54it/s, loss=0.146, v_num=1, val_loss=0.097, val_acc=0.973]\n",
            "Epoch 24: 100% 470/470 [00:12<00:00, 38.61it/s, loss=0.146, v_num=1, val_loss=0.0927, val_acc=0.975]\n",
            "Epoch 25:  91% 430/470 [00:12<00:01, 35.02it/s, loss=0.141, v_num=1, val_loss=0.0927, val_acc=0.975]\n",
            "Epoch 25:  92% 434/470 [00:12<00:01, 35.09it/s, loss=0.141, v_num=1, val_loss=0.0927, val_acc=0.975]\n",
            "Validating:  10% 4/40 [00:00<00:01, 35.57it/s]\u001b[A\n",
            "Epoch 25:  94% 441/470 [00:12<00:00, 35.18it/s, loss=0.141, v_num=1, val_loss=0.0927, val_acc=0.975]\n",
            "Epoch 25:  95% 448/470 [00:12<00:00, 35.27it/s, loss=0.141, v_num=1, val_loss=0.0927, val_acc=0.975]\n",
            "Validating:  45% 18/40 [00:00<00:00, 39.57it/s]\u001b[A\n",
            "Epoch 25:  97% 455/470 [00:12<00:00, 35.38it/s, loss=0.141, v_num=1, val_loss=0.0927, val_acc=0.975]\n",
            "Epoch 25:  98% 462/470 [00:13<00:00, 35.44it/s, loss=0.141, v_num=1, val_loss=0.0927, val_acc=0.975]\n",
            "Validating:  80% 32/40 [00:00<00:00, 40.58it/s]\u001b[A\n",
            "Epoch 25: 100% 470/470 [00:13<00:00, 35.52it/s, loss=0.141, v_num=1, val_loss=0.0951, val_acc=0.974]\n",
            "Epoch 26:  91% 430/470 [00:12<00:01, 35.36it/s, loss=0.154, v_num=1, val_loss=0.0951, val_acc=0.974]\n",
            "Epoch 26:  92% 434/470 [00:12<00:01, 35.47it/s, loss=0.154, v_num=1, val_loss=0.0951, val_acc=0.974]\n",
            "Validating:  12% 5/40 [00:00<00:00, 41.64it/s]\u001b[A\n",
            "Epoch 26:  94% 441/470 [00:12<00:00, 35.57it/s, loss=0.154, v_num=1, val_loss=0.0951, val_acc=0.974]\n",
            "Epoch 26:  95% 448/470 [00:12<00:00, 35.67it/s, loss=0.154, v_num=1, val_loss=0.0951, val_acc=0.974]\n",
            "Epoch 26:  97% 455/470 [00:12<00:00, 35.78it/s, loss=0.154, v_num=1, val_loss=0.0951, val_acc=0.974]\n",
            "Validating:  62% 25/40 [00:00<00:00, 43.49it/s]\u001b[A\n",
            "Epoch 26:  98% 462/470 [00:12<00:00, 35.88it/s, loss=0.154, v_num=1, val_loss=0.0951, val_acc=0.974]\n",
            "Epoch 26: 100% 470/470 [00:13<00:00, 35.98it/s, loss=0.154, v_num=1, val_loss=0.0976, val_acc=0.973]\n",
            "Epoch 27:  91% 430/470 [00:11<00:01, 37.45it/s, loss=0.152, v_num=1, val_loss=0.0976, val_acc=0.973]\n",
            "Epoch 27:  92% 434/470 [00:11<00:00, 37.56it/s, loss=0.152, v_num=1, val_loss=0.0976, val_acc=0.973]\n",
            "Validating:  12% 5/40 [00:00<00:00, 42.96it/s]\u001b[A\n",
            "Epoch 27:  94% 441/470 [00:11<00:00, 37.65it/s, loss=0.152, v_num=1, val_loss=0.0976, val_acc=0.973]\n",
            "Epoch 27:  95% 448/470 [00:11<00:00, 37.73it/s, loss=0.152, v_num=1, val_loss=0.0976, val_acc=0.973]\n",
            "Epoch 27:  97% 455/470 [00:12<00:00, 37.82it/s, loss=0.152, v_num=1, val_loss=0.0976, val_acc=0.973]\n",
            "Validating:  62% 25/40 [00:00<00:00, 44.40it/s]\u001b[A\n",
            "Epoch 27:  98% 462/470 [00:12<00:00, 37.92it/s, loss=0.152, v_num=1, val_loss=0.0976, val_acc=0.973]\n",
            "Epoch 27: 100% 470/470 [00:12<00:00, 38.00it/s, loss=0.152, v_num=1, val_loss=0.1, val_acc=0.974]   \n",
            "Epoch 28:  91% 430/470 [00:11<00:01, 37.75it/s, loss=0.169, v_num=1, val_loss=0.1, val_acc=0.974]\n",
            "Epoch 28:  92% 434/470 [00:11<00:00, 37.88it/s, loss=0.169, v_num=1, val_loss=0.1, val_acc=0.974]\n",
            "Validating:  12% 5/40 [00:00<00:00, 46.59it/s]\u001b[A\n",
            "Epoch 28:  94% 441/470 [00:11<00:00, 37.98it/s, loss=0.169, v_num=1, val_loss=0.1, val_acc=0.974]\n",
            "Epoch 28:  95% 448/470 [00:11<00:00, 38.06it/s, loss=0.169, v_num=1, val_loss=0.1, val_acc=0.974]\n",
            "Epoch 28:  97% 455/470 [00:11<00:00, 38.14it/s, loss=0.169, v_num=1, val_loss=0.1, val_acc=0.974]\n",
            "Validating:  62% 25/40 [00:00<00:00, 44.85it/s]\u001b[A\n",
            "Epoch 28:  98% 462/470 [00:12<00:00, 38.23it/s, loss=0.169, v_num=1, val_loss=0.1, val_acc=0.974]\n",
            "Epoch 28: 100% 470/470 [00:12<00:00, 38.26it/s, loss=0.169, v_num=1, val_loss=0.0991, val_acc=0.971]\n",
            "Epoch 29:  91% 430/470 [00:11<00:01, 38.01it/s, loss=0.159, v_num=1, val_loss=0.0991, val_acc=0.971]\n",
            "Epoch 29:  92% 434/470 [00:11<00:00, 38.13it/s, loss=0.159, v_num=1, val_loss=0.0991, val_acc=0.971]\n",
            "Validating:  12% 5/40 [00:00<00:00, 44.50it/s]\u001b[A\n",
            "Epoch 29:  94% 441/470 [00:11<00:00, 38.23it/s, loss=0.159, v_num=1, val_loss=0.0991, val_acc=0.971]\n",
            "Epoch 29:  95% 448/470 [00:11<00:00, 38.32it/s, loss=0.159, v_num=1, val_loss=0.0991, val_acc=0.971]\n",
            "Epoch 29:  97% 455/470 [00:11<00:00, 38.42it/s, loss=0.159, v_num=1, val_loss=0.0991, val_acc=0.971]\n",
            "Validating:  62% 25/40 [00:00<00:00, 45.47it/s]\u001b[A\n",
            "Epoch 29:  98% 462/470 [00:11<00:00, 38.51it/s, loss=0.159, v_num=1, val_loss=0.0991, val_acc=0.971]\n",
            "Epoch 29: 100% 470/470 [00:12<00:00, 38.57it/s, loss=0.159, v_num=1, val_loss=0.0948, val_acc=0.973]\n",
            "Epoch 30:  91% 430/470 [00:12<00:01, 35.62it/s, loss=0.173, v_num=1, val_loss=0.0948, val_acc=0.973]\n",
            "Epoch 30:  92% 434/470 [00:12<00:01, 35.73it/s, loss=0.173, v_num=1, val_loss=0.0948, val_acc=0.973]\n",
            "Validating:  10% 4/40 [00:00<00:00, 36.49it/s]\u001b[A\n",
            "Validating:  20% 8/40 [00:00<00:00, 36.96it/s]\u001b[A\n",
            "Epoch 30:  94% 441/470 [00:12<00:00, 35.45it/s, loss=0.173, v_num=1, val_loss=0.0948, val_acc=0.973]\n",
            "Epoch 30:  95% 448/470 [00:12<00:00, 35.53it/s, loss=0.173, v_num=1, val_loss=0.0948, val_acc=0.973]\n",
            "Validating:  48% 19/40 [00:00<00:00, 30.16it/s]\u001b[A\n",
            "Epoch 30:  97% 455/470 [00:12<00:00, 35.59it/s, loss=0.173, v_num=1, val_loss=0.0948, val_acc=0.973]\n",
            "Epoch 30:  98% 462/470 [00:12<00:00, 35.69it/s, loss=0.173, v_num=1, val_loss=0.0948, val_acc=0.973]\n",
            "Epoch 30: 100% 469/470 [00:13<00:00, 35.75it/s, loss=0.173, v_num=1, val_loss=0.0948, val_acc=0.973]\n",
            "Epoch 30: 100% 470/470 [00:13<00:00, 35.76it/s, loss=0.173, v_num=1, val_loss=0.0926, val_acc=0.974]\n",
            "Epoch 31:  91% 430/470 [00:12<00:01, 35.21it/s, loss=0.148, v_num=1, val_loss=0.0926, val_acc=0.974]\n",
            "Epoch 31:  92% 434/470 [00:12<00:01, 35.31it/s, loss=0.148, v_num=1, val_loss=0.0926, val_acc=0.974]\n",
            "Validating:  10% 4/40 [00:00<00:00, 39.85it/s]\u001b[A\n",
            "Epoch 31:  94% 441/470 [00:12<00:00, 35.41it/s, loss=0.148, v_num=1, val_loss=0.0926, val_acc=0.974]\n",
            "Epoch 31:  95% 448/470 [00:12<00:00, 35.49it/s, loss=0.148, v_num=1, val_loss=0.0926, val_acc=0.974]\n",
            "Validating:  48% 19/40 [00:00<00:00, 41.83it/s]\u001b[A\n",
            "Epoch 31:  97% 455/470 [00:12<00:00, 35.58it/s, loss=0.148, v_num=1, val_loss=0.0926, val_acc=0.974]\n",
            "Epoch 31:  98% 462/470 [00:12<00:00, 35.66it/s, loss=0.148, v_num=1, val_loss=0.0926, val_acc=0.974]\n",
            "Validating:  85% 34/40 [00:00<00:00, 40.53it/s]\u001b[A\n",
            "Epoch 31: 100% 470/470 [00:13<00:00, 35.69it/s, loss=0.148, v_num=1, val_loss=0.0959, val_acc=0.974]\n",
            "Epoch 31: 100% 470/470 [00:13<00:00, 35.62it/s, loss=0.148, v_num=1, val_loss=0.0959, val_acc=0.974]\n",
            "Testing: 100% 79/79 [00:01<00:00, 44.47it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': tensor(0.9736)}\n",
            "--------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rA0E9UBu7_Nn",
        "outputId": "1c3ac481-9235-4a3d-93be-ac25ecc70bb2"
      },
      "source": [
        "!python3 training/run_experiment.py --model_class=MLP --data_class=MNIST --max_epochs=5 --gpus=0,"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: You have set progress_bar_refresh_rate < 20 on Google Colab. This may crash. Consider using progress_bar_refresh_rate >= 20 in Trainer.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "GPU available: True, used: True\n",
            "TPU available: None, using: 0 TPU cores\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "2021-07-26 00:16:15.099055: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "\n",
            "  | Name          | Type     | Params\n",
            "-------------------------------------------\n",
            "0 | model         | MLP      | 936 K \n",
            "1 | model.dropout | Dropout  | 0     \n",
            "2 | model.fc1     | Linear   | 803 K \n",
            "3 | model.fc2     | Linear   | 131 K \n",
            "4 | model.fc3     | Linear   | 1.3 K \n",
            "5 | train_acc     | Accuracy | 0     \n",
            "6 | val_acc       | Accuracy | 0     \n",
            "7 | test_acc      | Accuracy | 0     \n",
            "-------------------------------------------\n",
            "936 K     Trainable params\n",
            "0         Non-trainable params\n",
            "936 K     Total params\n",
            "Epoch 0:  91% 430/470 [00:12<00:01, 35.76it/s, loss=0.21, v_num=2, val_loss=2.33, val_acc=0.0664] \n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 0:  93% 436/470 [00:12<00:00, 35.90it/s, loss=0.21, v_num=2, val_loss=2.33, val_acc=0.0664]\n",
            "Epoch 0:  94% 442/470 [00:12<00:00, 35.95it/s, loss=0.21, v_num=2, val_loss=2.33, val_acc=0.0664]\n",
            "Epoch 0:  95% 448/470 [00:12<00:00, 36.01it/s, loss=0.21, v_num=2, val_loss=2.33, val_acc=0.0664]\n",
            "Validating:  45% 18/40 [00:00<00:00, 40.78it/s]\u001b[A\n",
            "Epoch 0:  97% 454/470 [00:12<00:00, 36.06it/s, loss=0.21, v_num=2, val_loss=2.33, val_acc=0.0664]\n",
            "Epoch 0:  98% 460/470 [00:12<00:00, 36.13it/s, loss=0.21, v_num=2, val_loss=2.33, val_acc=0.0664]\n",
            "Epoch 0:  99% 466/470 [00:12<00:00, 36.15it/s, loss=0.21, v_num=2, val_loss=2.33, val_acc=0.0664]\n",
            "Epoch 0: 100% 470/470 [00:13<00:00, 35.98it/s, loss=0.21, v_num=2, val_loss=0.156, val_acc=0.955]\n",
            "Epoch 1:  91% 430/470 [00:12<00:01, 34.71it/s, loss=0.165, v_num=2, val_loss=0.156, val_acc=0.955]\n",
            "Epoch 1:  92% 432/470 [00:12<00:01, 34.80it/s, loss=0.165, v_num=2, val_loss=0.156, val_acc=0.955]\n",
            "Epoch 1:  93% 438/470 [00:12<00:00, 34.86it/s, loss=0.165, v_num=2, val_loss=0.156, val_acc=0.955]\n",
            "Epoch 1:  94% 444/470 [00:12<00:00, 34.93it/s, loss=0.165, v_num=2, val_loss=0.156, val_acc=0.955]\n",
            "Validating:  35% 14/40 [00:00<00:00, 40.51it/s]\u001b[A\n",
            "Epoch 1:  96% 450/470 [00:12<00:00, 34.96it/s, loss=0.165, v_num=2, val_loss=0.156, val_acc=0.955]\n",
            "Epoch 1:  97% 456/470 [00:13<00:00, 35.00it/s, loss=0.165, v_num=2, val_loss=0.156, val_acc=0.955]\n",
            "Validating:  65% 26/40 [00:00<00:00, 39.46it/s]\u001b[A\n",
            "Epoch 1:  98% 462/470 [00:13<00:00, 35.08it/s, loss=0.165, v_num=2, val_loss=0.156, val_acc=0.955]\n",
            "Epoch 1: 100% 468/470 [00:13<00:00, 35.14it/s, loss=0.165, v_num=2, val_loss=0.156, val_acc=0.955]\n",
            "Epoch 1: 100% 470/470 [00:13<00:00, 35.04it/s, loss=0.165, v_num=2, val_loss=0.112, val_acc=0.969]\n",
            "Epoch 2:  91% 430/470 [00:11<00:01, 36.66it/s, loss=0.128, v_num=2, val_loss=0.112, val_acc=0.969]\n",
            "Epoch 2:  92% 432/470 [00:11<00:01, 36.76it/s, loss=0.128, v_num=2, val_loss=0.112, val_acc=0.969]\n",
            "Epoch 2:  93% 438/470 [00:11<00:00, 36.80it/s, loss=0.128, v_num=2, val_loss=0.112, val_acc=0.969]\n",
            "Epoch 2:  94% 444/470 [00:12<00:00, 36.86it/s, loss=0.128, v_num=2, val_loss=0.112, val_acc=0.969]\n",
            "Validating:  38% 15/40 [00:00<00:00, 40.78it/s]\u001b[A\n",
            "Epoch 2:  96% 450/470 [00:12<00:00, 36.88it/s, loss=0.128, v_num=2, val_loss=0.112, val_acc=0.969]\n",
            "Epoch 2:  97% 456/470 [00:12<00:00, 36.93it/s, loss=0.128, v_num=2, val_loss=0.112, val_acc=0.969]\n",
            "Epoch 2:  98% 462/470 [00:12<00:00, 36.96it/s, loss=0.128, v_num=2, val_loss=0.112, val_acc=0.969]\n",
            "Epoch 2: 100% 468/470 [00:12<00:00, 37.01it/s, loss=0.128, v_num=2, val_loss=0.112, val_acc=0.969]\n",
            "Epoch 2: 100% 470/470 [00:12<00:00, 36.87it/s, loss=0.128, v_num=2, val_loss=0.11, val_acc=0.969] \n",
            "Epoch 3:  91% 430/470 [00:12<00:01, 34.11it/s, loss=0.143, v_num=2, val_loss=0.11, val_acc=0.969]\n",
            "Epoch 3:  92% 432/470 [00:12<00:01, 34.20it/s, loss=0.143, v_num=2, val_loss=0.11, val_acc=0.969]\n",
            "Epoch 3:  93% 438/470 [00:12<00:00, 34.29it/s, loss=0.143, v_num=2, val_loss=0.11, val_acc=0.969]\n",
            "Epoch 3:  94% 444/470 [00:12<00:00, 34.36it/s, loss=0.143, v_num=2, val_loss=0.11, val_acc=0.969]\n",
            "Epoch 3:  96% 450/470 [00:13<00:00, 34.44it/s, loss=0.143, v_num=2, val_loss=0.11, val_acc=0.969]\n",
            "Validating:  50% 20/40 [00:00<00:00, 41.10it/s]\u001b[A\n",
            "Epoch 3:  97% 456/470 [00:13<00:00, 34.47it/s, loss=0.143, v_num=2, val_loss=0.11, val_acc=0.969]\n",
            "Epoch 3:  98% 462/470 [00:13<00:00, 34.53it/s, loss=0.143, v_num=2, val_loss=0.11, val_acc=0.969]\n",
            "Validating:  80% 32/40 [00:00<00:00, 39.29it/s]\u001b[A\n",
            "Epoch 3: 100% 470/470 [00:13<00:00, 34.49it/s, loss=0.143, v_num=2, val_loss=0.0905, val_acc=0.975]\n",
            "Epoch 4:  91% 430/470 [00:12<00:01, 35.28it/s, loss=0.12, v_num=2, val_loss=0.0905, val_acc=0.975] \n",
            "Epoch 4:  92% 433/470 [00:12<00:01, 35.39it/s, loss=0.12, v_num=2, val_loss=0.0905, val_acc=0.975]\n",
            "Epoch 4:  94% 440/470 [00:12<00:00, 35.50it/s, loss=0.12, v_num=2, val_loss=0.0905, val_acc=0.975]\n",
            "Validating:  25% 10/40 [00:00<00:00, 43.54it/s]\u001b[A\n",
            "Epoch 4:  95% 447/470 [00:12<00:00, 35.62it/s, loss=0.12, v_num=2, val_loss=0.0905, val_acc=0.975]\n",
            "Epoch 4:  97% 454/470 [00:12<00:00, 35.65it/s, loss=0.12, v_num=2, val_loss=0.0905, val_acc=0.975]\n",
            "Validating:  60% 24/40 [00:00<00:00, 41.27it/s]\u001b[A\n",
            "Epoch 4:  98% 461/470 [00:12<00:00, 35.75it/s, loss=0.12, v_num=2, val_loss=0.0905, val_acc=0.975]\n",
            "Epoch 4: 100% 468/470 [00:13<00:00, 35.86it/s, loss=0.12, v_num=2, val_loss=0.0905, val_acc=0.975]\n",
            "Epoch 4: 100% 470/470 [00:13<00:00, 35.76it/s, loss=0.12, v_num=2, val_loss=0.0875, val_acc=0.974]\n",
            "Epoch 4: 100% 470/470 [00:13<00:00, 35.65it/s, loss=0.12, v_num=2, val_loss=0.0875, val_acc=0.974]\n",
            "Testing: 100% 79/79 [00:01<00:00, 43.68it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': tensor(0.9779, device='cuda:0')}\n",
            "--------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ts6lDPQw-5Du",
        "outputId": "a9f7e4ec-b6bd-4efe-ba60-3d046a2caa2d"
      },
      "source": [
        "!python3 training/run_experiment.py --model_class=MLP --data_class=MNIST --max_epochs=5 --fc2=256 --gpus=0,"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: You have set progress_bar_refresh_rate < 20 on Google Colab. This may crash. Consider using progress_bar_refresh_rate >= 20 in Trainer.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "GPU available: True, used: True\n",
            "TPU available: None, using: 0 TPU cores\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "2021-07-26 00:32:35.089778: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "\n",
            "  | Name          | Type     | Params\n",
            "-------------------------------------------\n",
            "0 | model         | MLP      | 1.1 M \n",
            "1 | model.dropout | Dropout  | 0     \n",
            "2 | model.fc1     | Linear   | 803 K \n",
            "3 | model.fc2     | Linear   | 262 K \n",
            "4 | model.fc3     | Linear   | 2.6 K \n",
            "5 | train_acc     | Accuracy | 0     \n",
            "6 | val_acc       | Accuracy | 0     \n",
            "7 | test_acc      | Accuracy | 0     \n",
            "-------------------------------------------\n",
            "1.1 M     Trainable params\n",
            "0         Non-trainable params\n",
            "1.1 M     Total params\n",
            "Epoch 0:  91% 430/470 [00:12<00:01, 34.84it/s, loss=0.217, v_num=5, val_loss=2.33, val_acc=0.0234]\n",
            "Epoch 0:  92% 432/470 [00:12<00:01, 34.94it/s, loss=0.217, v_num=5, val_loss=2.33, val_acc=0.0234]\n",
            "Epoch 0:  93% 438/470 [00:12<00:00, 35.03it/s, loss=0.217, v_num=5, val_loss=2.33, val_acc=0.0234]\n",
            "Epoch 0:  94% 444/470 [00:12<00:00, 35.10it/s, loss=0.217, v_num=5, val_loss=2.33, val_acc=0.0234]\n",
            "Epoch 0:  96% 450/470 [00:12<00:00, 35.17it/s, loss=0.217, v_num=5, val_loss=2.33, val_acc=0.0234]\n",
            "Validating:  50% 20/40 [00:00<00:00, 42.43it/s]\u001b[A\n",
            "Epoch 0:  97% 456/470 [00:12<00:00, 35.23it/s, loss=0.217, v_num=5, val_loss=2.33, val_acc=0.0234]\n",
            "Epoch 0:  98% 462/470 [00:13<00:00, 35.31it/s, loss=0.217, v_num=5, val_loss=2.33, val_acc=0.0234]\n",
            "Epoch 0: 100% 468/470 [00:13<00:00, 35.39it/s, loss=0.217, v_num=5, val_loss=2.33, val_acc=0.0234]\n",
            "Epoch 0: 100% 470/470 [00:13<00:00, 35.25it/s, loss=0.217, v_num=5, val_loss=0.132, val_acc=0.963]\n",
            "Epoch 1:  91% 430/470 [00:12<00:01, 35.60it/s, loss=0.147, v_num=5, val_loss=0.132, val_acc=0.963]\n",
            "Epoch 1:  92% 432/470 [00:12<00:01, 35.69it/s, loss=0.147, v_num=5, val_loss=0.132, val_acc=0.963]\n",
            "Epoch 1:  93% 438/470 [00:12<00:00, 35.73it/s, loss=0.147, v_num=5, val_loss=0.132, val_acc=0.963]\n",
            "Epoch 1:  94% 444/470 [00:12<00:00, 35.81it/s, loss=0.147, v_num=5, val_loss=0.132, val_acc=0.963]\n",
            "Validating:  35% 14/40 [00:00<00:00, 39.57it/s]\u001b[A\n",
            "Epoch 1:  96% 450/470 [00:12<00:00, 35.81it/s, loss=0.147, v_num=5, val_loss=0.132, val_acc=0.963]\n",
            "Epoch 1:  97% 456/470 [00:12<00:00, 35.82it/s, loss=0.147, v_num=5, val_loss=0.132, val_acc=0.963]\n",
            "Validating:  65% 26/40 [00:00<00:00, 37.30it/s]\u001b[A\n",
            "Epoch 1:  98% 462/470 [00:12<00:00, 35.86it/s, loss=0.147, v_num=5, val_loss=0.132, val_acc=0.963]\n",
            "Epoch 1: 100% 468/470 [00:13<00:00, 35.91it/s, loss=0.147, v_num=5, val_loss=0.132, val_acc=0.963]\n",
            "Epoch 1: 100% 470/470 [00:13<00:00, 35.77it/s, loss=0.147, v_num=5, val_loss=0.104, val_acc=0.968]\n",
            "Epoch 2:  91% 430/470 [00:12<00:01, 34.42it/s, loss=0.119, v_num=5, val_loss=0.104, val_acc=0.968]\n",
            "Epoch 2:  92% 432/470 [00:12<00:01, 34.51it/s, loss=0.119, v_num=5, val_loss=0.104, val_acc=0.968]\n",
            "Epoch 2:  93% 438/470 [00:12<00:00, 34.57it/s, loss=0.119, v_num=5, val_loss=0.104, val_acc=0.968]\n",
            "Validating:  22% 9/40 [00:00<00:00, 39.76it/s]\u001b[A\n",
            "Epoch 2:  94% 444/470 [00:12<00:00, 34.61it/s, loss=0.119, v_num=5, val_loss=0.104, val_acc=0.968]\n",
            "Epoch 2:  96% 450/470 [00:12<00:00, 34.68it/s, loss=0.119, v_num=5, val_loss=0.104, val_acc=0.968]\n",
            "Epoch 2:  97% 456/470 [00:13<00:00, 34.75it/s, loss=0.119, v_num=5, val_loss=0.104, val_acc=0.968]\n",
            "Epoch 2:  98% 462/470 [00:13<00:00, 34.80it/s, loss=0.119, v_num=5, val_loss=0.104, val_acc=0.968]\n",
            "Validating:  80% 32/40 [00:00<00:00, 39.92it/s]\u001b[A\n",
            "Epoch 2: 100% 470/470 [00:13<00:00, 34.76it/s, loss=0.119, v_num=5, val_loss=0.0935, val_acc=0.972]\n",
            "Epoch 3:  91% 430/470 [00:12<00:01, 35.12it/s, loss=0.12, v_num=5, val_loss=0.0935, val_acc=0.972] \n",
            "Epoch 3:  92% 432/470 [00:12<00:01, 35.22it/s, loss=0.12, v_num=5, val_loss=0.0935, val_acc=0.972]\n",
            "Epoch 3:  93% 438/470 [00:12<00:00, 35.29it/s, loss=0.12, v_num=5, val_loss=0.0935, val_acc=0.972]\n",
            "Epoch 3:  94% 444/470 [00:12<00:00, 35.38it/s, loss=0.12, v_num=5, val_loss=0.0935, val_acc=0.972]\n",
            "Validating:  35% 14/40 [00:00<00:00, 43.07it/s]\u001b[A\n",
            "Epoch 3:  96% 450/470 [00:12<00:00, 35.47it/s, loss=0.12, v_num=5, val_loss=0.0935, val_acc=0.972]\n",
            "Epoch 3:  97% 456/470 [00:12<00:00, 35.55it/s, loss=0.12, v_num=5, val_loss=0.0935, val_acc=0.972]\n",
            "Epoch 3:  98% 462/470 [00:12<00:00, 35.64it/s, loss=0.12, v_num=5, val_loss=0.0935, val_acc=0.972]\n",
            "Epoch 3: 100% 468/470 [00:13<00:00, 35.70it/s, loss=0.12, v_num=5, val_loss=0.0935, val_acc=0.972]\n",
            "Epoch 3: 100% 470/470 [00:13<00:00, 35.71it/s, loss=0.12, v_num=5, val_loss=0.0958, val_acc=0.973]\n",
            "Epoch 4:  91% 430/470 [00:11<00:01, 36.09it/s, loss=0.111, v_num=5, val_loss=0.0958, val_acc=0.973]\n",
            "Epoch 4:  92% 432/470 [00:11<00:01, 36.17it/s, loss=0.111, v_num=5, val_loss=0.0958, val_acc=0.973]\n",
            "Epoch 4:  93% 438/470 [00:12<00:00, 36.25it/s, loss=0.111, v_num=5, val_loss=0.0958, val_acc=0.973]\n",
            "Epoch 4:  94% 444/470 [00:12<00:00, 36.32it/s, loss=0.111, v_num=5, val_loss=0.0958, val_acc=0.973]\n",
            "Epoch 4:  96% 450/470 [00:12<00:00, 36.40it/s, loss=0.111, v_num=5, val_loss=0.0958, val_acc=0.973]\n",
            "Validating:  50% 20/40 [00:00<00:00, 41.84it/s]\u001b[A\n",
            "Epoch 4:  97% 456/470 [00:12<00:00, 36.45it/s, loss=0.111, v_num=5, val_loss=0.0958, val_acc=0.973]\n",
            "Epoch 4:  98% 462/470 [00:12<00:00, 36.51it/s, loss=0.111, v_num=5, val_loss=0.0958, val_acc=0.973]\n",
            "Epoch 4: 100% 470/470 [00:12<00:00, 36.47it/s, loss=0.111, v_num=5, val_loss=0.0736, val_acc=0.976]\n",
            "Epoch 4: 100% 470/470 [00:12<00:00, 36.36it/s, loss=0.111, v_num=5, val_loss=0.0736, val_acc=0.976]\n",
            "Testing: 100% 79/79 [00:01<00:00, 43.58it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': tensor(0.9771, device='cuda:0')}\n",
            "--------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsk5I41r_WD0",
        "outputId": "763f9fc5-7400-4e95-de23-53dccfcfdda5"
      },
      "source": [
        "!python3 training/run_experiment.py --model_class=MLP --data_class=MNIST --max_epochs=5 --fc2=256 --gpus=0,"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: You have set progress_bar_refresh_rate < 20 on Google Colab. This may crash. Consider using progress_bar_refresh_rate >= 20 in Trainer.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "GPU available: True, used: True\n",
            "TPU available: None, using: 0 TPU cores\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "2021-07-26 00:54:12.921053: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "\n",
            "  | Name          | Type     | Params\n",
            "-------------------------------------------\n",
            "0 | model         | MLP      | 1.1 M \n",
            "1 | model.dropout | Dropout  | 0     \n",
            "2 | model.fc1     | Linear   | 803 K \n",
            "3 | model.fc2     | Linear   | 262 K \n",
            "4 | model.fc3     | Linear   | 2.6 K \n",
            "5 | train_acc     | Accuracy | 0     \n",
            "6 | val_acc       | Accuracy | 0     \n",
            "7 | test_acc      | Accuracy | 0     \n",
            "-------------------------------------------\n",
            "1.1 M     Trainable params\n",
            "0         Non-trainable params\n",
            "1.1 M     Total params\n",
            "Epoch 0:  91% 430/470 [00:11<00:01, 38.15it/s, loss=0.131, v_num=6, val_loss=2.33, val_acc=0.0234]\n",
            "Epoch 0:  92% 434/470 [00:11<00:00, 38.23it/s, loss=0.131, v_num=6, val_loss=2.33, val_acc=0.0234]\n",
            "Validating:  10% 4/40 [00:00<00:00, 39.35it/s]\u001b[A\n",
            "Epoch 0:  94% 440/470 [00:11<00:00, 38.25it/s, loss=0.131, v_num=6, val_loss=2.33, val_acc=0.0234]\n",
            "Epoch 0:  95% 446/470 [00:11<00:00, 38.28it/s, loss=0.131, v_num=6, val_loss=2.33, val_acc=0.0234]\n",
            "Epoch 0:  96% 452/470 [00:11<00:00, 38.34it/s, loss=0.131, v_num=6, val_loss=2.33, val_acc=0.0234]\n",
            "Epoch 0:  97% 458/470 [00:11<00:00, 38.36it/s, loss=0.131, v_num=6, val_loss=2.33, val_acc=0.0234]\n",
            "Validating:  70% 28/40 [00:00<00:00, 40.74it/s]\u001b[A\n",
            "Epoch 0:  99% 464/470 [00:12<00:00, 38.41it/s, loss=0.131, v_num=6, val_loss=2.33, val_acc=0.0234]\n",
            "Epoch 0: 100% 470/470 [00:12<00:00, 38.23it/s, loss=0.131, v_num=6, val_loss=0.114, val_acc=0.965]\n",
            "Epoch 1:  91% 430/470 [00:12<00:01, 35.70it/s, loss=0.0832, v_num=6, val_loss=0.114, val_acc=0.965]\n",
            "Epoch 1:  92% 432/470 [00:12<00:01, 35.80it/s, loss=0.0832, v_num=6, val_loss=0.114, val_acc=0.965]\n",
            "Epoch 1:  93% 438/470 [00:12<00:00, 35.83it/s, loss=0.0832, v_num=6, val_loss=0.114, val_acc=0.965]\n",
            "Validating:  22% 9/40 [00:00<00:00, 39.02it/s]\u001b[A\n",
            "Epoch 1:  94% 444/470 [00:12<00:00, 35.88it/s, loss=0.0832, v_num=6, val_loss=0.114, val_acc=0.965]\n",
            "Epoch 1:  96% 450/470 [00:12<00:00, 35.93it/s, loss=0.0832, v_num=6, val_loss=0.114, val_acc=0.965]\n",
            "Epoch 1:  97% 456/470 [00:12<00:00, 35.99it/s, loss=0.0832, v_num=6, val_loss=0.114, val_acc=0.965]\n",
            "Epoch 1:  98% 462/470 [00:12<00:00, 36.04it/s, loss=0.0832, v_num=6, val_loss=0.114, val_acc=0.965]\n",
            "Validating:  80% 32/40 [00:00<00:00, 40.30it/s]\u001b[A\n",
            "Epoch 1: 100% 470/470 [00:13<00:00, 35.99it/s, loss=0.0832, v_num=6, val_loss=0.0969, val_acc=0.97]\n",
            "Epoch 2:  91% 430/470 [00:12<00:01, 35.82it/s, loss=0.0573, v_num=6, val_loss=0.0969, val_acc=0.97]\n",
            "Epoch 2:  92% 432/470 [00:12<00:01, 35.92it/s, loss=0.0573, v_num=6, val_loss=0.0969, val_acc=0.97]\n",
            "Epoch 2:  93% 438/470 [00:12<00:00, 35.97it/s, loss=0.0573, v_num=6, val_loss=0.0969, val_acc=0.97]\n",
            "Epoch 2:  94% 444/470 [00:12<00:00, 36.04it/s, loss=0.0573, v_num=6, val_loss=0.0969, val_acc=0.97]\n",
            "Validating:  35% 14/40 [00:00<00:00, 41.53it/s]\u001b[A\n",
            "Epoch 2:  96% 450/470 [00:12<00:00, 36.13it/s, loss=0.0573, v_num=6, val_loss=0.0969, val_acc=0.97]\n",
            "Epoch 2:  97% 456/470 [00:12<00:00, 36.22it/s, loss=0.0573, v_num=6, val_loss=0.0969, val_acc=0.97]\n",
            "Epoch 2:  98% 462/470 [00:12<00:00, 36.31it/s, loss=0.0573, v_num=6, val_loss=0.0969, val_acc=0.97]\n",
            "Epoch 2: 100% 468/470 [00:12<00:00, 36.39it/s, loss=0.0573, v_num=6, val_loss=0.0969, val_acc=0.97]\n",
            "Epoch 2: 100% 470/470 [00:12<00:00, 36.29it/s, loss=0.0573, v_num=6, val_loss=0.0886, val_acc=0.972]\n",
            "Epoch 3:  91% 430/470 [00:11<00:01, 36.07it/s, loss=0.0491, v_num=6, val_loss=0.0886, val_acc=0.972]\n",
            "Epoch 3:  92% 432/470 [00:11<00:01, 36.15it/s, loss=0.0491, v_num=6, val_loss=0.0886, val_acc=0.972]\n",
            "Epoch 3:  93% 438/470 [00:12<00:00, 36.19it/s, loss=0.0491, v_num=6, val_loss=0.0886, val_acc=0.972]\n",
            "Epoch 3:  94% 444/470 [00:12<00:00, 36.24it/s, loss=0.0491, v_num=6, val_loss=0.0886, val_acc=0.972]\n",
            "Validating:  35% 14/40 [00:00<00:00, 39.69it/s]\u001b[A\n",
            "Epoch 3:  96% 450/470 [00:12<00:00, 36.29it/s, loss=0.0491, v_num=6, val_loss=0.0886, val_acc=0.972]\n",
            "Epoch 3:  97% 456/470 [00:12<00:00, 36.34it/s, loss=0.0491, v_num=6, val_loss=0.0886, val_acc=0.972]\n",
            "Epoch 3:  98% 462/470 [00:12<00:00, 36.39it/s, loss=0.0491, v_num=6, val_loss=0.0886, val_acc=0.972]\n",
            "Epoch 3: 100% 468/470 [00:12<00:00, 36.45it/s, loss=0.0491, v_num=6, val_loss=0.0886, val_acc=0.972]\n",
            "Epoch 3: 100% 470/470 [00:12<00:00, 36.45it/s, loss=0.0491, v_num=6, val_loss=0.0908, val_acc=0.972]\n",
            "Epoch 4:  91% 430/470 [00:12<00:01, 35.11it/s, loss=0.0517, v_num=6, val_loss=0.0908, val_acc=0.972]\n",
            "Epoch 4:  92% 432/470 [00:12<00:01, 35.20it/s, loss=0.0517, v_num=6, val_loss=0.0908, val_acc=0.972]\n",
            "Epoch 4:  93% 438/470 [00:12<00:00, 35.26it/s, loss=0.0517, v_num=6, val_loss=0.0908, val_acc=0.972]\n",
            "Epoch 4:  94% 444/470 [00:12<00:00, 35.34it/s, loss=0.0517, v_num=6, val_loss=0.0908, val_acc=0.972]\n",
            "Validating:  35% 14/40 [00:00<00:00, 40.35it/s]\u001b[A\n",
            "Epoch 4:  96% 450/470 [00:12<00:00, 35.39it/s, loss=0.0517, v_num=6, val_loss=0.0908, val_acc=0.972]\n",
            "Epoch 4:  97% 456/470 [00:12<00:00, 35.44it/s, loss=0.0517, v_num=6, val_loss=0.0908, val_acc=0.972]\n",
            "Epoch 4:  98% 462/470 [00:13<00:00, 35.50it/s, loss=0.0517, v_num=6, val_loss=0.0908, val_acc=0.972]\n",
            "Validating:  82% 33/40 [00:00<00:00, 40.84it/s]\u001b[A\n",
            "Epoch 4: 100% 470/470 [00:13<00:00, 35.55it/s, loss=0.0517, v_num=6, val_loss=0.0926, val_acc=0.973]\n",
            "Epoch 4: 100% 470/470 [00:13<00:00, 35.46it/s, loss=0.0517, v_num=6, val_loss=0.0926, val_acc=0.973]\n",
            "Testing: 100% 79/79 [00:01<00:00, 41.58it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': tensor(0.9770, device='cuda:0')}\n",
            "--------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}